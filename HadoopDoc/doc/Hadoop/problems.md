# Hadoop相关问题集

## Hadoop

* hadoop读文件是一个一个Block读的。那一个文件有多个block 分布在不同机器，是会按照block的顺序在多台机器顺序去读，还是并发同时在多台机器读，每次都把这台机器存在的block读完？

    >答：  
    >并发的在多台机器读。每个Map对应一个Block，至于是否“每次吧这台机器存在的Block读完”，取决于其对应的Map什么时候启动。

* RM分配资源的过程是怎样的，是怎样去计算可分配资源的？ RM现在可分配的资源是NodeManager汇报给RM后，RM汇总得到的？已经使用的资源NodeManage是汇报实际使用的资源还是汇报分配后剩余的？

    >答：   
    >每个应用（App）在提交（commit）时，会提出资源需求，我们程序中没有指定是因为我们为了编程和控制方便，建议使用默认值（由管理员预设）。在启动NM时，需要设定每个NM可以贡献的资源，在RM那里汇总就是整个集群可以掌控的资源。分配的基本准则是哪里有可以分配的资源，就分配在哪里，尽量满足应用需求。分配的具体工作由调度器（scheduler）负责，根据具体实现的不同，会考虑负载均衡，优先级，用户等情况。
      
    >已经使用的资源是在RM中计算的，不是NM汇报的，并且此“已经使用的资源”是名义上的，不一定是真实发生的。例如：App申请一个Map需要1G内存，RM分配了1G内存，并在增加“已经使用的资源”1G，但实际此Map使用的内存可以少于1G。  
    
    >注：*资源在现阶段仅包括内存，设计中，资源包括：内存，CPU，网络，硬盘。*

* container在hadoop2里面是不是会复用的，就是Task结束后container还能执行其它task么？
    >答：  
    >以我们的配置方式来说，是不会复用的。

    >上述回答不完全准确，所以加了“以我们的配置方式来说”，YARN框架是资源管理框架，它只负责资源的创建和管理，至于如何使用资源，由下一层的计算框架控制，以我们的应用来说，就是由MRv2来控制。原则是Container是不复用的。但是有个uber模式，可以在单个container中顺序地执行一个Job的Map和Reduce，这对于小App是有利的。
